{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from os import environ\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, Normalizer, binarize\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check that the expected variables were passed the the notbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'clinical_data' not in environ:\n",
    "    print \"Please set the environment variable clinical_data\"\n",
    "    sys.exit(1)\n",
    "    \n",
    "if 'gene_expression_data' not in environ:\n",
    "    print \"Please set the environment variable gene_expression_data\"\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the patient and gene expression data. We have to mash up the data a bit so that we can join the two datasets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-91f805316de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in patient data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m patients = pd.read_csv(config['datasets']['patients'],\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gleason_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     index_col=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in patient data.\n",
    "patients_file = environ['clinical_data']\n",
    "patients = pd.read_csv(patients_file,\n",
    "    sep=\"\\t\",\n",
    "    usecols=['sample', 'gleason_score'],\n",
    "    index_col=0)\n",
    "\n",
    "# Read in gene expression data.\n",
    "gene_expression_file = environ['gene_expression_data']\n",
    "gene_expression = pd.read_csv(gene_expression_file,\n",
    "    sep='\\t',\n",
    "    index_col='gene_id')\n",
    "\n",
    "# Transpose gene expression data it so we can join with patients. We also\n",
    "# group by \"index\", take the first record so that we remove any duplicate\n",
    "# patients.\n",
    "gene_expression = gene_expression.\\\n",
    "    T.\\\n",
    "    reset_index().\\\n",
    "    groupby(\"index\").\\\n",
    "    first()\n",
    "\n",
    "# Rename our index to sample. Now our patients and gene expression data frames\n",
    "# have the same index names.\n",
    "gene_expression.index.rename(\"sample\", inplace=True)\n",
    "\n",
    "# Use only the first 12 characters in the sample id -- the rest is unknown.\n",
    "gene_expression.index = gene_expression.index.str.slice(0,12)\n",
    "\n",
    "# Join our tables.\n",
    "patient_gene_expression = patients.join(gene_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the feature matrix and response variables we will train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patient_gene_expression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-88f0146ae010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_gene_expression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gleason_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_gene_expression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgleason_score\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patient_gene_expression' is not defined"
     ]
    }
   ],
   "source": [
    "X = patient_gene_expression.drop('gleason_score').as_matrix()\n",
    "Y = patient_gene_expression.gleason_score >= 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our pipeline that we're going to use for hyperparameter selection, cross-validation, and model building. Then specify the parameter distributions that we're going to search across. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our pipeline that we're going to use for hyperparameter selection,\n",
    "# cross-validation, and model building.\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC())),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=1000))\n",
    "])\n",
    "\n",
    "# Specify parameter distributions that we're going to search across.\n",
    "parameter_grid = {\n",
    "    \"random_forest__max_depth\": [5, 10, 15, 20, 25],\n",
    "    \"random_forest__max_features\": [2**n for n in range(3, 12)]\n",
    "}\n",
    "\n",
    "# Define a grid search across the parameter distribution for our pipeline.\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "    param_grid=parameter_grid,\n",
    "    n_jobs=8,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-fold nested cross-validation to select hyperparameters using the grid search method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of results that we're going to append to.\n",
    "cross_validation_results_list = []\n",
    "grid_search_results_list = []\n",
    "support_list = []\n",
    "\n",
    "# Iterate through stratified k-folds\n",
    "for fold, (train, test) in enumerate(StratifiedKFold(Y, n_folds=6)):\n",
    "\n",
    "    print(\"Iterating through fold #{} of 6.\".format(fold+1))\n",
    "\n",
    "    # Search for best parameters using training data. \n",
    "    grid_search.fit(X[train], Y[train])\n",
    "\n",
    "    # Save grid search parameters\n",
    "    for grid_score in grid_search.grid_scores_:\n",
    "        grid_search_result = pd.Series(grid_score.parameters)\n",
    "        grid_search_result['score'] = grid_score.mean_validation_score\n",
    "        grid_search_result['fold'] = fold\n",
    "        grid_search_results_list.append(grid_search_result)\n",
    "\n",
    "    # Select the best estimator.\n",
    "    model = grid_search.best_estimator_\n",
    "\n",
    "    # Get the list of supports selected from the feature_selection step\n",
    "    support = {\n",
    "        'fold': fold,\n",
    "        'support': model.named_steps['feature_selection'].get_support()\n",
    "    }\n",
    "\n",
    "    # Add grid search params to our support.\n",
    "    support.update(grid_search.best_params_)\n",
    "\n",
    "    # Append this to our list of supports.\n",
    "    support_list.append(support)\n",
    "\n",
    "    # Make predictions for the output.\n",
    "    probabilities = model.predict_proba(X[test])\n",
    "\n",
    "    # Calculate false/true positive rates\n",
    "    false_positive_rate, true_positive_rate, roc_thresholds = roc_curve(Y[test], probabilities[:, 1])\n",
    "\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(Y[test], probabilities[:, 1])\n",
    "\n",
    "    metrics = {\n",
    "        'fold': fold+1,\n",
    "        'false_positive_rate': false_positive_rate,\n",
    "        'true_positive_rate': true_positive_rate,\n",
    "        'area_under_curve': auc(false_positive_rate, true_positive_rate),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_thresholds': roc_thresholds,\n",
    "        'precision_recall_thresholds': pr_thresholds\n",
    "    }\n",
    "\n",
    "    # Add our hyperparameters to our results.\n",
    "    metrics.update(grid_search.best_params_)\n",
    "\n",
    "    # Add our results to the data frame so that we can track parameters and \n",
    "    cross_validation_results_list.append(metrics)\n",
    "    \n",
    "# Convert our results to data frames for easy processing.\n",
    "support_results = pd.DataFrame(support_list)\n",
    "cross_validation_results = pd.DataFrame(cross_validation_results_list)\n",
    "grid_search_results = pd.DataFrame(grid_search_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model parameters per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, sharex='col', sharey='row')\n",
    "\n",
    "for fold, ax in enumerate(axes.flatten()):\n",
    "\n",
    "    # Look at the search results for this fold.\n",
    "    fold_grid_search_results = grid_search_results[grid_search_results.fold == fold].\\\n",
    "        drop('fold', 1).\\\n",
    "        pivot('random_forest__max_depth', 'random_forest__max_features')\n",
    "    \n",
    "    x, y = meshgrid(fold_grid_search_results.columns.levels[1].values,\n",
    "            fold_grid_search_results.index.values)\n",
    "\n",
    "    z = fold_grid_search_results.values\n",
    "\n",
    "    ax.contourf(x, y, z)\n",
    "\n",
    "    ax.set_xscale('log', basex=2)\n",
    "\n",
    "fig.suptitle(\"Random Forest Grid Search Results Per Fold\")\n",
    "fig.text(0.5, 0.02, 'Feature Count', ha='center')\n",
    "fig.text(0.04, 0.5, 'Depth', va='center', rotation='vertical')\n",
    "fig.savefig(\"random-forest-parameters-per-fold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receiver operating characteristic curve per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "for _, row in cross_validation_results.iterrows():\n",
    "    ax.plot(row.false_positive_rate, row.true_positive_rate)\n",
    "\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "fig.suptitle(\"Receiver operating characteristic curve per fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall vs Threshold per Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "for _, row in cross_validation_results.iterrows():\n",
    "    ax.plot(row.precision_recall_thresholds, row.precision[:-1], 'r')\n",
    "    ax.plot(row.precision_recall_thresholds, row.recall[:-1], 'b')\n",
    "\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Precision / Recall\")\n",
    "fig.suptitle(\"Precision and Recall vs Threshold per Fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, perform a grid search using all available data and save the resulting model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = grid_search.fit(X, Y)\n",
    "\n",
    "with open('pipeline.pickle', 'wb') as f:\n",
    "    pickle.dump(models.best_estimator_, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
